{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNkaM2uXXKItWFAXtz4cglS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaquim-teixeira/HVGFGL-metabolite/blob/main/notebooks/HVGFGL_Kidney_Data_VI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarchical Variational Graph Fused Lasso (HVGFGL)\n",
        "\n",
        "This notebook provides an implementation of the **Hierarchical Variational Graph Fused Lasso (HVGFGL)** introduced in  \n",
        "[*A Hierarchical Variational Graph Fused Lasso for Recovering Relative Rates in Spatial Compositional Data*](https://arxiv.org/abs/2509.20636).  \n",
        "\n",
        "It contains the core code required to apply HVGFGL to real imaging mass spectrometry (IMS) dataâ€”specifically, mouse kidney data from [Wang et al., 2022](https://pubmed.ncbi.nlm.nih.gov/35132243/).  \n",
        "The corresponding results and analyses are presented in **Section 6** of the manuscript.  \n",
        "\n",
        "---\n",
        "\n",
        "## Inputs\n",
        "- **Dataset**: Mouse kidney IMS data from Wang et al., 2022.  \n",
        "- **Preprocessing**: Data is standardized and filtered to match the experimental setup described in the manuscript.  \n",
        "\n",
        "---\n",
        "\n",
        "## Outputs\n",
        "Running this notebook will generate:  \n",
        "- **Variational Parameters** for HVGFGL on data."
      ],
      "metadata": {
        "id": "MOQld2VbExSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dependencies and Utils\n",
        "# Mount into drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "%cd '/content/drive/MyDrive/'\n",
        "from google.colab import files\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Dirichlet, Multinomial, Laplace, Gamma,InverseGamma, Normal, MultivariateNormal\n",
        "import time\n",
        "import scipy as sp\n",
        "from scipy.spatial import KDTree\n",
        "import pandas as pd\n",
        "import matplotlib.colors as mcolors\n",
        "import time\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"You are using device: %s\" % device)\n",
        "\n",
        "\n",
        "\n",
        "def sample_neg_mult_gamma_cont (n,p,size):\n",
        "    p0 = 1-p.sum(axis=-1)\n",
        "    #try:\n",
        "    #    n_sample = torch.distributions.Gamma(n,1/(1/p0-1)).rsample([size])\n",
        "    #except:\n",
        "    n_sample = torch.distributions.Gamma(n,1/(1/(p0+ 1e-40)-1) + 1e-40).rsample([size])\n",
        "    val = (n_sample/((1-p0+1e-40))).unsqueeze(-1)*p.unsqueeze(0)\n",
        "    tst=torch.distributions.Normal(val, torch.sqrt(val+1e-40)).rsample()\n",
        "    return(tst)\n",
        "\n",
        "def find_neighbors(points, threshold):\n",
        "    tree = KDTree(points)\n",
        "    neighbors = tree.query_ball_tree(tree, threshold)\n",
        "    return neighbors\n",
        "\n",
        "def create_adjacency_matrix(points, neighbors):\n",
        "    n = len(points)\n",
        "    adjacency_matrix = np.zeros((n, n), dtype=int)\n",
        "\n",
        "    for i, neighbor_list in enumerate(neighbors):\n",
        "        for neighbor in neighbor_list:\n",
        "            adjacency_matrix[i][neighbor] = 1\n",
        "            adjacency_matrix[neighbor][i] = 1\n",
        "    return adjacency_matrix\n",
        "def columnwise_corr(A, B, eps=1e-8):\n",
        "    # A and B should be shape (n, p)\n",
        "    A_mean = A.mean(dim=0)\n",
        "    B_mean = B.mean(dim=0)\n",
        "\n",
        "    A_centered = A - A_mean\n",
        "    B_centered = B - B_mean\n",
        "\n",
        "    numerator = (A_centered * B_centered).sum(dim=0)\n",
        "    denom = (A_centered.square().sum(dim=0).sqrt() * B_centered.square().sum(dim=0).sqrt())\n",
        "\n",
        "    corr = numerator / (denom + eps)  # eps for numerical stability\n",
        "    return corr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5sFbDIpoLPn",
        "outputId": "22c6371a-0ce0-4c2c-a2bd-f497fbf39213",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title HVGFGL Lasso\n",
        "def sample_neg_mult_gamma_cont_cens (n,p,size,cens):\n",
        "    p0 = 1-(p*(cens)).sum(axis=-1)\n",
        "    n_sample = torch.distributions.Gamma(n,1/(1/(p0+ 1e-40)-1) + 1e-40).rsample([size])\n",
        "\n",
        "    val = (n_sample/((1-p0+1e-40))).unsqueeze(-1)*(p*(cens)).unsqueeze(0)\n",
        "    tst = torch.distributions.Normal(val, torch.sqrt(val+1e-40)).rsample()\n",
        "    return(tst)\n",
        "\n",
        "def elbo_lasso_cens(theta_q_loc, x, lam, adj, cens, lods, cr, samp_size, n_samp, cens_exp, gamma_1_raw, gamma_2_raw, lam_1_raw, lam_2_raw, dat_exp, a1, a2, cens_inf):\n",
        "\n",
        "    q_lam = torch.distributions.Gamma(torch.exp(lam_1_raw), torch.exp(lam_2_raw))\n",
        "    lam_samp = q_lam.rsample([n_samp])\n",
        "    q_gamma = torch.distributions.Gamma(torch.exp(gamma_1_raw), torch.exp(gamma_2_raw))\n",
        "    q_gamma_samp = q_gamma.rsample([n_samp])\n",
        "\n",
        "    p1, E, q = q_gamma_samp.shape\n",
        "    N = adj.max().item() + 1\n",
        "    sums = torch.zeros(p1, N, q, dtype=torch.float32, device=device)\n",
        "\n",
        "    sums.scatter_add_(1, a1, 1 / q_gamma_samp)\n",
        "    sums.scatter_add_(1, a2, 1 / q_gamma_samp)\n",
        "\n",
        "    theta_q = torch.distributions.Normal(theta_q_loc, (1 / sums).sqrt())\n",
        "    samps_q = theta_q.rsample([1]).squeeze(0)\n",
        "    theta = torch.softmax(samps_q,dim=-1)\n",
        "\n",
        "    wot = sample_neg_mult_gamma_cont_cens(dat_exp.sum(axis=-1)[:,~cr], theta[:,~cr,:], samp_size, cens_exp[:,~cr,:])\n",
        "\n",
        "    soft_indicator = torch.sigmoid(1e5 * (lods[~cr] - wot))\n",
        "    vals = (((torch.sigmoid(1e5 * (soft_indicator.mean(axis=-1) - 1))) * 2.).mean(axis=0) + 1e-90).log()\n",
        "\n",
        "    log_theta = samps_q - torch.logsumexp(samps_q-cens_inf, axis=-1).unsqueeze(-1)\n",
        "    log_likelihood = (dat_exp[~cens_exp] * log_theta[~cens_exp]).sum() / n_samp\n",
        "\n",
        "\n",
        "    log_likelihood = log_likelihood + vals.sum(axis=1).mean()\n",
        "\n",
        "    mu = (samps_q[:, adj[:, 0], :] - samps_q[:, adj[:, 1], :]).unsqueeze(0)\n",
        "    laplace_prior = -(((mu.abs()* (1 / q_gamma_samp.unsqueeze(1))).sum([-1, -2])).mean())\n",
        "    local_prior = -(q_gamma_samp / lam_samp.unsqueeze(1)).sum([-1, -2]).mean()\n",
        "\n",
        "    ent_gamma = q_gamma.log_prob(q_gamma_samp).sum([-1, -2]).mean()\n",
        "    ent_norm = theta_q.log_prob(samps_q).sum([-1, -2]).mean()\n",
        "\n",
        "    lam_prior = torch.distributions.Gamma(1, lam)\n",
        "    lam_kl = torch.distributions.kl_divergence(q_lam, lam_prior)\n",
        "    return log_likelihood + laplace_prior + local_prior - ent_norm - ent_gamma - lam_kl.sum()\n"
      ],
      "metadata": {
        "id": "LO7zA55IoJnN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read Kidney Tic Data\n",
        "df = pd.read_csv('kidney_M2_tic.csv')\n",
        "pts=np.array([df.x, df.y]).T\n",
        "df = df.drop(columns = ['x', 'y','Unnamed: 0'])\n",
        "print(df.shape)\n",
        "df = df.dropna(axis=1, how='all')\n",
        "df = np.floor(df)\n",
        "\n",
        "cens = torch.tensor(np.array(df.eq(df.min())))\n",
        "data = np.array(df)\n",
        "data = np.floor(data)\n",
        "data = torch.from_numpy(data).to(torch.float64)\n",
        "lods = torch.from_numpy(np.array(df.min())).expand(data.size(0),-1).to(device)\n",
        "cens_inf = cens.clone()*1.\n",
        "cens_inf[cens] = torch.inf\n",
        "cr = (cens.sum(axis=1)==0)\n",
        "\n",
        "df.columns = df.columns.str.strip()             # Remove leading/trailing spaces\n",
        "df.columns = df.columns.str.replace(' ', '_')   # Replace spaces with underscores\n",
        "df.columns = df.columns.str.replace(r'\\W', '')  # Remove special characters (non-alphanumeric)\n",
        "df.columns = df.columns.str.replace('/', '_')     # Replace forward slashes with underscores\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBzkMNIPohUP",
        "outputId": "dc9f6eb6-50cd-4dbb-90dc-a9cea6be4d17",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15403, 353)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get Adjecency Graph\n",
        "from scipy.sparse import coo_matrix\n",
        "neighbors = find_neighbors(pts, 1.5)\n",
        "n_nodes = len(neighbors)\n",
        "\n",
        "# Create sparse adjacency from edge list\n",
        "rows = []\n",
        "cols = []\n",
        "vals = []\n",
        "\n",
        "for i, nbrs in enumerate(neighbors):\n",
        "    for j in nbrs:\n",
        "        rows.append(i)\n",
        "        cols.append(j)\n",
        "        vals.append(1)  # or use weights if available\n",
        "\n",
        "# Determine size from max index\n",
        "n = max(max(cols), n_nodes) + 1\n",
        "\n",
        "# Create sparse adjacency matrix (COO format)\n",
        "adj = coo_matrix((vals, (rows, cols)), shape=(n, n))\n",
        "edges = np.vstack((adj.row, adj.col))  # shape: [2, N_edges]\n",
        "sorted_edges = np.sort(edges, axis=0)  # shape [2, N_edges]\n",
        "# Remove duplicates using structured array trick\n",
        "edges_unique = np.unique(sorted_edges, axis=1).transpose()\n",
        "inds = edges_unique[:,0] == edges_unique[:,1]\n",
        "edges_unique = edges_unique[~inds]\n",
        "edges_unique = torch.from_numpy(edges_unique)\n"
      ],
      "metadata": {
        "id": "YSnyPQ7TpmKW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initialize model parameters and hyperparameters\n",
        "\n",
        "data = torch.tensor(data, dtype=torch.float32, device=device)\n",
        "cpd = data.clone()\n",
        "lam_use = data.mean(dim=0).cpu()\n",
        "\n",
        "# Parameters\n",
        "theta_q_loc = torch.log((cpd + 1) / (cpd + data.size(1)).sum(dim=1, keepdim=True)).clone()\n",
        "theta_q_loc = theta_q_loc.to(dtype=torch.float32, device=device).requires_grad_(True)\n",
        "\n",
        "gamma_1_raw = torch.ones((edges_unique.size(0), data.size(1)), dtype=torch.float32, device=device).requires_grad_(True)\n",
        "gamma_2_raw = torch.tensor(torch.ones((edges_unique.size(0),data.size(1)), dtype=torch.float32)*(lam_use).log(),device=device,requires_grad=True)\n",
        "\n",
        "lam_1_raw = torch.zeros_like(lam_use, device=device).requires_grad_(True)\n",
        "lam_2_raw = lam_use.log().to(dtype=torch.float32, device=device).clone().requires_grad_(True)\n",
        "lam_group = data.var(dim=0).to(device)\n",
        "\n",
        "# Training settings\n",
        "num_steps = 1_000_000\n",
        "samp_size = 15\n",
        "n_samp = 2\n",
        "losses = torch.zeros(num_steps, device=device)\n",
        "\n",
        "# Expand data/censoring\n",
        "cens = cens.to(device)\n",
        "cens_inf = cens_inf.to(device)\n",
        "edges_unique = edges_unique.to(device)\n",
        "\n",
        "dat_exp = data.unsqueeze(0).expand(n_samp, -1, -1)\n",
        "cens_exp = cens.unsqueeze(0).expand(n_samp, -1, -1)\n",
        "\n",
        "# Graph-related setup\n",
        "N = edges_unique.max().item() + 1\n",
        "feat_dim = gamma_2_raw.size(-1)\n",
        "\n",
        "sums = torch.zeros(n_samp, N, feat_dim, dtype=torch.float32, device=device)\n",
        "a1 = edges_unique[:, 0].unsqueeze(0).unsqueeze(-1).expand(n_samp, -1, feat_dim)\n",
        "a2 = edges_unique[:, 1].unsqueeze(0).unsqueeze(-1).expand(n_samp, -1, feat_dim)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(\n",
        "    [theta_q_loc, gamma_1_raw, gamma_2_raw, lam_1_raw, lam_2_raw],\n",
        "    lr=0.01,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHWrPwwYpPU-",
        "outputId": "6410ba0a-a263-4eed-8363-1523762789b1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2743434963.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  data = torch.tensor(data, dtype=torch.float32, device=device)\n",
            "/tmp/ipython-input-2743434963.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  gamma_2_raw = torch.tensor(torch.ones((edges_unique.size(0),data.size(1)), dtype=torch.float32)*(lam_use).log(),device=device,requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run model and save output\n",
        "for step in range(num_steps):\n",
        "  st=time.time()\n",
        "  optimizer.zero_grad()\n",
        "  loss = - elbo_lasso_cens(\n",
        "          theta_q_loc, data, lam_group, edges_unique, cens, lods, cr,\n",
        "          samp_size, n_samp, cens_exp, gamma_1_raw, gamma_2_raw, lam_1_raw, lam_2_raw, dat_exp, a1, a2, cens_inf\n",
        "      )\n",
        "\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  losses[step] = loss.detach().item()\n",
        "  with torch.no_grad():\n",
        "    if step !=0:\n",
        "        if step % 5000 == 0:\n",
        "          print(step)\n",
        "          val = (losses[(step-5000):step].mean())\n",
        "          if val>TH:\n",
        "            break\n",
        "          else:\n",
        "            print((val - TH)/loss.item())\n",
        "            TH = val\n",
        "            torch.save({\n",
        "            'step': step,\n",
        "            'theta_q_loc': theta_q_loc.detach().cpu(),\n",
        "            'gamma_1_raw': gamma_1_raw.detach().cpu(),\n",
        "            'gamma_2_raw': gamma_2_raw.detach().cpu(),\n",
        "            'lam_1_raw': lam_1_raw.detach().cpu(),\n",
        "            'lam_2_raw': lam_2_raw.detach().cpu(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss.item()\n",
        "            }, 'model_checkpoint.pt')\n",
        "            #print(len(losses)/num_steps)\n",
        "            #print(time.time()-st)\n",
        "            #window = 5000\n",
        "            #running_avg = np.convolve(np.array(losses), np.ones(window)/window, mode='valid')\n",
        "            #plt.plot(range(5000), running_avg[-5000:], color='red', label=f'{window}-point running average')\n",
        "            # plt.show()\n",
        "            # print((theta_q_loc/theta_q_loc.mean(axis=0,keepdims=True) - tic).pow(2).max(axis=0).values/tic.var(axis=0))\n",
        "  if step == 100:\n",
        "      torch.save({\n",
        "      'step': step,\n",
        "      'theta_q_loc': theta_q_loc.detach().cpu(),\n",
        "      'gamma_1_raw': gamma_1_raw.detach().cpu(),\n",
        "      'gamma_2_raw': gamma_2_raw.detach().cpu(),\n",
        "      'lam_1_raw': lam_1_raw.detach().cpu(),\n",
        "      'lam_2_raw': lam_2_raw.detach().cpu(),\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'loss': loss.item()\n",
        "      }, 'model_checkpoint.pt')\n",
        "      #print(len(losses)/num_steps)\n",
        "      #print(time.time()-st)\n",
        "      #window = 5000\n",
        "      #running_avg = np.convolve(np.array(losses), np.ones(window)/window, mode='valid')\n",
        "      #plt.plot(range(5000), running_avg[-5000:], color='red', label=f'{window}-point running average')\n",
        "      # plt.show()\n",
        "      # print((theta_q_loc/theta_q_loc.mean(axis=0,keepdims=True) - tic).pow(2).max(axis=0).values/tic.var(axis=0))\n",
        "      print('test complete')\n",
        "filename = 'real_data_theta_full_kidney.pt'\n",
        "print(filename)\n",
        "torch.save(theta_q_loc.cpu(), filename)\n",
        "file2 = 'real_data_losses_full_kidney.pt'\n",
        "torch.save(losses.cpu(), file2)"
      ],
      "metadata": {
        "id": "muVji-tlV4N9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}